{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">Models of categorization.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The inhabitants of the planet Boton love pushing buttons. There are many kinds of buttons on Boton: red buttons, blue buttons, big buttons, small buttons. In fact, there are four dimensions along which buttons vary:\n",
    "\n",
    "![](images/concepts.png)\n",
    "\n",
    "Not all buttons do the same thing when pushed. Some are harmless, but others are dangerous and self-destruct. As young Botonans grow up, they are taught which buttons are safe to push and which are unsafe. Unfortunately, there are no hard-and-fast rules about which buttons are safe or unsafe, so young Botonans must develop a scheme for categorizing the buttons. For example, a Botonan might observe the following:\n",
    "<a name=\"exemplars\"></a>\n",
    "\n",
    "![](images/exemplars.png)\n",
    "\n",
    "Clearly, it's not enough to say that all the blue buttons are safe because there is at least one blue button known to be unsafe. So, how do the Botonans determine which buttons are safe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Context Model : similarity\n",
    "As a cognitive scientist, you know a few different models of categorization that have been proposed. For example, you might remember the *context model* described by Medin and Schaffer (1978). The context model is an exemplar model: the probability that a stimulus is assigned to a category is based on its similarity to all the exemplars in that category.\n",
    "\n",
    "To use the context model, we represent each stimulus (button) as a vector. For example, we can represent a big square blue textured button as $\\mathbf{x}=[1, 0, 1, 1]$. Similarly, we can represent the stimulus which is small red cicular textured button as $\\mathbf{x}=[0, 1, 0, 1]$. Given this representation, we can now define a similarity function.\n",
    "\n",
    "> <a name=\"eq:similarity\"></a>The similarity $\\mathbb{S}$ of one stimulus $\\mathbf{x}$ to another stimulus $\\mathbf{y}$ is given by the following set of equations:\n",
    ">\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\mathbb{S}(\\mathbf{x}, \\mathbf{y}) &= \\prod_{i = 1}^m s(x_i, y_i)=s(x_1, y_1)\\cdot{}s(x_2, y_2)\\cdot{}\\ldots{}\\cdot{}s(x_m, y_m)\\\\\n",
    "s(x_i, y_i) &= \\left\\{\n",
    "\\begin{array}{rl} 1 & \\text{if } x_{i} = y_{i} \\\\\n",
    "   \\theta & \\text{if } x_{i} \\neq y_{i}\\end{array}\\right.\n",
    "   \\end{align*}\n",
    "$$\n",
    ">\n",
    "> where $\\theta$ is a constant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "42b5f9650074de12fe860e0cf5a0e87c",
     "grade": false,
     "grade_id": "calculate_similarity",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(x, y, theta=0.1):\n",
    "    \"\"\"Calculates the similarity between a stimulus x and a \n",
    "    stimulus y, where similarity is defined as:\n",
    "    \n",
    "        S(x, y) = s(x_1, y_1) * s(x_2, y_2) * ... * s(x_m, y_m)\n",
    "    \n",
    "    and:\n",
    "    \n",
    "        s(x_i, y_i) = 1 if x_i == y_i, theta otherwise\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : numpy arrays with shape (m,)\n",
    "        The stimuli to compute similarity between\n",
    "    theta : (optional) float\n",
    "        A parameter to the similarity function. When the function is\n",
    "        called without theta having been specified, it defaults to 0.1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float : the similarity between x and y\n",
    "    \n",
    "    \"\"\"\n",
    "    return theta**(np.sum(x!=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n",
    "x = np.array([1, 0, 1, 1])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "print(\"S(x, y) = {}\".format(calculate_similarity(x, y)))\n",
    "print(\"S(x, y, theta=0.3) = {}\".format(calculate_similarity(x, y, theta=0.3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Context Model: Categorization\n",
    "Now that we have defined the similarity between two stimuli, we can take a look at the equation for the context model. In the definition below, you can think of category $A$ as being the *safe buttons*, and category $B$ as being the *unsafe buttons*.\n",
    "\n",
    "> <a name=\"eq:context-model\"></a>The context model, which gives the probability that a novel stimulus $\\mathbf{x}$ belongs to category $A$ (as opposed to category $B$) is given by:\n",
    ">\n",
    "> $$\n",
    "P(A|\\mathbf{x}) = \\frac{\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})}{\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})+ \\sum_{\\mathbf{b} \\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})}\n",
    "$$\n",
    ">\n",
    "> where $\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})$ is the sum over the similarity of $\\mathbf{x}$ to all exemplars $\\mathbf{a}$ in category $A$, and $\\sum_{\\mathbf{b} \\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})$ is the sum over the similarity of $\\mathbf{x}$ to all exemplars $\\mathbf{b}$ in category $B$.\n",
    "\n",
    "Note that because $P(A|\\mathbf{x})$ is a probability, we can easily compute from it the probability that $\\mathbf{x}$ belongs to category $B$. The stimulus *must* belong to one of the two categories, thus $P(B|\\mathbf{x})=1-P(A|\\mathbf{x})$.\n",
    "\n",
    "\n",
    "where $\\mathbb{S}$ is the [similarity function](#eq:similarity) that we defined above and implemented in `calculate_similarity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a09f86d77a6a5e737de7d87fab61fa9b",
     "grade": false,
     "grade_id": "context_model",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def context_model(test_stimuli, exemplars, exemplar_categories, theta=0.1):\n",
    "    \"\"\"Computes the probability that each test stimulus belongs to \n",
    "    category A.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stimuli : numpy array with shape (n, m)\n",
    "        n stimuli, each with m features, to be classified (i.e. \n",
    "        compute P(A|x) for each x)\n",
    "    exemplars : numpy array with shape (k, m)\n",
    "        k exemplars, each with m features\n",
    "    exemplar_categories : numpy string array with shape (k,)\n",
    "        Categories for the k exemplars. You can assume the values of \n",
    "        exemplar_categories will always be either be \"A\" or \"B\".\n",
    "    theta : (optional) float\n",
    "        A parameter to pass to the similarity function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (n,) such that the i^th element \n",
    "    corresponds to P(A|test_stimuli[i])\n",
    "        \n",
    "    \"\"\"\n",
    "    probability = np.empty(len(test_stimuli))\n",
    "    for i in range(len(test_stimuli)):\n",
    "        SA, SB = 0, 0\n",
    "        for j in range(len(exemplars)):\n",
    "            if exemplar_categories[j]==\"A\":\n",
    "                SA += calculate_similarity(test_stimuli[i,:],exemplars[j,:],theta)\n",
    "            else:\n",
    "                SB += calculate_similarity(test_stimuli[i,:],exemplars[j,:],theta)\n",
    "                \n",
    "        probability[i] = SA/(SA+SB)\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n",
    "\n",
    "test_stimuli = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "test_exemplars = np.array([[1, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0]])\n",
    "test_exemplar_categories = np.array([\"B\", \"A\", \"A\", \"A\"])\n",
    "context_model(test_stimuli, test_exemplars, test_exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Context Model: Trying it out\n",
    "Now that you have an implementation of the context model, let's try it out! First, let's see how well it does at categorizing the [exemplars that we already have](#exemplars):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da1ed2c45d5c5d2262574a1c357e8dd5",
     "grade": false,
     "grade_id": "exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "safe_exemplars = np.array([\n",
    "    [0, 1, 1, 0], # circle / small / blue / solid\n",
    "    [1, 0, 1, 0], # square / big   / blue / solid\n",
    "    [1, 1, 0, 0], # square / small / red  / solid\n",
    "    [1, 1, 1, 1]  # square / small / blue / textured\n",
    "])\n",
    "unsafe_exemplars = np.array([\n",
    "    [1, 1, 0, 1], # square / small / red  / textured\n",
    "    [0, 0, 0, 1], # circle / big   / red  / textured\n",
    "    [0, 1, 1, 1], # circle / small / blue / textured\n",
    "    [0, 1, 0, 0]  # circle / small / red  / solid\n",
    "])\n",
    "all_exemplars = np.vstack([safe_exemplars, unsafe_exemplars])\n",
    "exemplar_categories = np.array([\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a250cf02b856312d738c1df018b17f99",
     "grade": false,
     "grade_id": "context_model_exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "context_model(all_exemplars, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Describe how well the context model does at categorizing the known exemplars. Does it give a higher value for $P(A|\\mathbf{x})$ for those $\\mathbf{x}$ which are actually in category $A$? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Context Model: New exemplars\n",
    "A young Botonan is strolling through the city, when a flash of blue and red is seen coming from an alleyway. Taking a closer look, the youngster discovers four buttons never before encountered:\n",
    "<a name=\"novel\"></a>\n",
    "\n",
    "![](images/novel.png)\n",
    "\n",
    "As a Botonan, this youngster feels a strong urge to push the buttons. However, the possibility that some of the buttons might be dangerous demands restraint. The Botonan pauses and takes a closer look.\n",
    "\n",
    "Let's see what the context model says about how likely these buttons are to be dangerous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8d38522078912c176dfccb80ddeda1e0",
     "grade": false,
     "grade_id": "novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "novel_stimuli = np.array([\n",
    "    [0, 0, 0, 0], # circle / big   / red  / solid\n",
    "    [1, 0, 0, 1], # square / big   / red  / textured\n",
    "    [1, 0, 1, 1], # square / big   / blue / textured\n",
    "    [0, 0, 1, 0]  # circle / big   / blue / solid\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ce20365830cd81be253dde86fa2a6699",
     "grade": false,
     "grade_id": "context_model_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "context_model(novel_stimuli, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">In words, what does the context model say? Which of these buttons are more likely to belong to category A (safe buttons)?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Prototype Model: Creating a prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "You also know of another model of categorization: the prototype model. This model is similar to the context model, but rather than comparing the new stimulus to all of the exemplars, it compares the new stimulus to the category *prototypes*. How do we know what the category prototype is? We can compute a prototype from a set of exemplars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6a00dadbf1ad9c096a79323dac1d631",
     "grade": false,
     "grade_id": "prototype",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def prototype(features):\n",
    "    \"\"\"\n",
    "    Compute the prototype features, based on the given features of\n",
    "    category members. The prototype should have a feature if half or\n",
    "    more of the category members have that feature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : numpy array with shape (n, m)\n",
    "        The first dimension corresponds to n category members, and the\n",
    "        second dimension to m features.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (m,) corresponding to the features\n",
    "    of the prototype of the category members\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return (np.mean(features,axis=0)>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n",
    "prototype(np.array([[0, 1], [0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<a name=\"prototypes\"></a>Check what your function returns for the \"safe button\" prototype and the \"unsafe button\" prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7dbae3e6a285d80a28e01efc1f40349c",
     "grade": false,
     "grade_id": "prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "safe_prototype = prototype(safe_exemplars)\n",
    "unsafe_prototype = prototype(unsafe_exemplars)\n",
    "print(\"Safe button prototype: {}\".format(safe_prototype))\n",
    "print(\"Unsafe button prototype: {}\".format(unsafe_prototype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Describe in words what the features of each prototype are (e.g., \"the safe button prototype is a [size], [color], [fill] [shape]\"). Remember that the first feature corresponds to shape, the second feature corresponds to size, the third feature corresponds to color, and the fourth feature corresponds to fill. (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Prototype Model: Categorization\n",
    "Now that we have a way of computing prototypes from our exemplars, let's take a look at the actual prototype model.\n",
    "\n",
    "<a name=\"eq:prototype\"></a>\n",
    "> The prototype model can be described by the following equation:\n",
    ">\n",
    "> $$\n",
    "P(A|\\mathbf{x})=\\frac{\\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_A)}{\\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_A) + \\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_B)}\n",
    "$$\n",
    ">\n",
    "> where $\\mathbb{S}$ is the [similarity function defined above](#eq:similarity), $\\mathbf{x}$ is the novel stimulus, $\\mathbf{\\mu}_A$ is the prototype of category $A$, and $\\mathbf{\\mu}_B$ is the prototype of category $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4651a98b2961132f9e078f991930bded",
     "grade": false,
     "grade_id": "prototype_model",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def prototype_model(test_stimuli, exemplars, exemplar_categories, theta=0.1):\n",
    "    \"\"\"Computes the probability that each test stimulus belongs to \n",
    "    category A.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stimuli : numpy array with shape (n, m)\n",
    "        n stimuli, each with m features, to be classified (i.e. \n",
    "        compute P(A|x) for each x)\n",
    "    exemplars : numpy array with shape (k, m)\n",
    "        k exemplars, each with m features\n",
    "    exemplar_categories : numpy string array with shape (k,)\n",
    "        Categories for the k exemplars. You can assume the values of \n",
    "        exemplar_categories will always be either be \"A\" or \"B\".\n",
    "    theta : (optional) float\n",
    "        A parameter to pass to the similarity function. If theta is not\n",
    "        specified, it defaults to 0.1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (n,) such that the i^th element \n",
    "    corresponds to P(A|test_stimuli[i])\n",
    "        \n",
    "    \"\"\"\n",
    "    # compute prototypes\n",
    "    prototype_A = prototype(exemplars[exemplar_categories==\"A\"])\n",
    "    prototype_B = prototype(exemplars[exemplar_categories==\"B\"])\n",
    "    # compute probability for each test item\n",
    "    probability = np.empty(len(test_stimuli))\n",
    "    for i in range(len(test_stimuli)):\n",
    "        SA = calculate_similarity(test_stimuli[i,:],prototype_A,theta)\n",
    "        SB = calculate_similarity(test_stimuli[i,:],prototype_B,theta)\n",
    "        probability[i] = SA/(SA+SB)\n",
    "    \n",
    "    return probability\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n",
    "test_stimuli = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "test_exemplars = np.array([[1, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0]])\n",
    "test_exemplar_categories = np.array([\"B\", \"A\", \"A\", \"A\"])\n",
    "\n",
    "prototype_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Prototype Model: Categorizing the prototype\n",
    "Let's see how well the prototype model does at categorizing the prototypes of safe and unsafe buttons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c70dfe4b5fec0bfef36244c092da1095",
     "grade": false,
     "grade_id": "prototype_model_prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "prototypes = np.vstack([safe_prototype, unsafe_prototype])\n",
    "prototype_model(prototypes, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Prototype Model: New exemplars\n",
    "Now let's see what the prototype model would say about the [unknown buttons](#novel) that our young Botonan has encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67fb759baa91c2dccbe0deec412b5de8",
     "grade": false,
     "grade_id": "prototype_model_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "prototype_model(novel_stimuli, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">What does the prototype model say? Which of these buttons are more likely to belong to category A (safe buttons)? If the prototype model is an accurate model of how Botonans categorize concepts, do you think they would push any of the buttons? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Comparing Models\n",
    "As we develop computational models of cognition, it is not enough to look at a single model and declare that it is good or bad. What is it good or bad in relation to? We must always *compare* our models, in order to get a better sense of how the space of models behave on a particular type of problem.\n",
    "\n",
    "We have now analyzed the context model and prototype model independently, but we have not compared them. First, let's compare how they both behave on the exemplars that have already been observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f7a04a1868c626309012331c4173a3a",
     "grade": false,
     "grade_id": "comparing_exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context model on exemplars:    {}\".format(context_model(all_exemplars, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on exemplars:  {}\".format(prototype_model(all_exemplars, all_exemplars, exemplar_categories)))\n",
    "print(\"True exemplar categories:      {}\".format(exemplar_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Which model is more accurate at predicting the exemplar categories? \n",
    "Even though the models have seen these exemplars, and know their true categories, they do not predict the category labels with 100% certainty. Why is this the case? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now let's take a look at how well the models perform on the prototypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bcbb16fbc14de466a97d2fbcdee86952",
     "grade": false,
     "grade_id": "comparing_prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context model on prototypes:    {}\".format(context_model(prototypes, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on prototypes:  {}\".format(prototype_model(prototypes, all_exemplars, exemplar_categories)))\n",
    "print(\"True prototype categories:      {}\".format(np.array([\"A\", \"B\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Which model is more accurate at predicting the prototypes? Why?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Finally, let's take a look at how the models predict the novel stimuli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d2e8068a4a1fb1099ccd1259e4bb037d",
     "grade": false,
     "grade_id": "comparing_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context model on novel:   {}\".format(context_model(novel_stimuli, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on novel: {}\".format(prototype_model(novel_stimuli, all_exemplars, exemplar_categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the true categories of the novel stimuli were $[B, B, B, A]$, which model would be more advantageous in this scenario (remember that category $B$ is the unsafe buttons)? If the true categories of the novel stimuli were $[B, B, A, A]$? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
